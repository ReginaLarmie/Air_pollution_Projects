---
title: "new_EPA"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}
# Load required packages
library(RAQSAPI)
library(purrr)
library(readr)

# EPA credentials
aqs_credentials(username = "rnl34@case.edu", key = "copperhawk19")

# Vector of site numbers 
site_numbers <- c("0034", "0038", "0045", "0060", "0065")  

# Define date range
start_date <- as.Date("2024-11-01")
end_date   <- as.Date("2025-05-01")

# Loop through and download data for each site
epa_data_list <- map(site_numbers, function(site) {
  aqs_sampledata_by_site(
    parameter = "88101",              # PM2.5
    bdate = start_date,
    edate = end_date,
    stateFIPS = "39",                 # Ohio
    countycode = "035",               # Cuyahoga
    sitenum = site,
    return_header = FALSE
  )
})

# Assign a name to each element that is its site number
names(epa_data_list) <- site_numbers

# View one dataset (site "0060")
head(epa_data_list[["0060"]])

#Save each to its own CSV file
walk2(epa_data_list, names(epa_data_list), ~ write_csv(.x, paste0("epa_pm25_site_", .y, ".csv")))
```

```{r}

# Combine All Sites' Data and Assess NA Distribution

library(dplyr)

# Combine all site data into one tibble for inspection
epa_all_data <- bind_rows(epa_data_list, .id = "site_number")

# Count NA values in each column
na_counts <- sapply(epa_all_data, function(col) sum(is.na(col)))
na_counts <- sort(na_counts, decreasing = TRUE)

# Display NA counts per column
na_counts

# Identifing Columns Where Most Values Are NA

# Total number of rows
total_rows <- nrow(epa_all_data)

# Threshold: show columns where fewer than 5% of rows are NOT NA
mostly_na_cols <- names(na_counts[na_counts > 0 & na_counts < total_rows * 0.05])

# View summary of those columns
epa_all_data %>%
  select(all_of(mostly_na_cols)) %>%
  summary()
```


#  Combine All EPA Site Data into One Data Frame
```{r}

library(dplyr)

# Combine all site data into one data frame
epa_all_sites_raw <- bind_rows(epa_data_list, .id = "site_number")  # The .id is unnecessary

# Filter to Keep Only PM2.5 1-HOUR Measurements
epa_1hr_clean <- epa_all_sites_raw %>%
  filter(sample_duration == "1 HOUR", !is.na(sample_measurement)) %>%
  mutate(
    datetime_local = as.POSIXct(paste(date_local, time_local),
                                format = "%Y-%m-%d %H:%M",
                                tz = "America/New_York"),
    date = as.Date(datetime_local)
  )

# Preview the Cleaned 1-Hour Data
glimpse(epa_1hr_clean)
```

```{r}

# Count Number of NA Values in Each Column

na_counts_1hr <- sapply(epa_1hr_clean, function(col) sum(is.na(col)))
na_counts_1hr <- sort(na_counts_1hr, decreasing = TRUE)

# View number of NA values per column
na_counts_1hr

```
# Calculate Daily Averages by Site
```{r}
epa_1hr_daily_avg <- epa_1hr_clean %>%
  group_by(site_number, date) %>%
  summarise(daily_avg_pm25 = mean(sample_measurement, na.rm = TRUE), .groups = "drop")


# Daily PM2.5 Trend for All Sites
library(ggplot2)
library(dplyr)

# Create plots for each site
unique_sites <- unique(epa_1hr_daily_avg$site_number)

for (site in unique_sites) {
  site_data <- epa_1hr_daily_avg %>% filter(site_number == site)

  p <- ggplot(site_data, aes(x = date, y = daily_avg_pm25)) +
    geom_line(color = "steelblue", linewidth = 0.6) +
    labs(
      title = paste("Daily Average PM2.5 (1-Hour Data) - Site", site),
      x = "Date",
      y = expression("PM"[2.5]*" (µg/m³)")
    ) +
    scale_x_date(date_breaks = "1 month", date_labels = "%b\n%Y") +
    theme_minimal(base_size = 13)

  print(p)  # Show the plot

  # Optionally save
  ggsave(filename = paste0("pm25_daily_avg_site_", site, ".png"), plot = p, width = 8, height = 4.5)
}
```



```{r}
library(readr)
library(dplyr)
library(lubridate)

# Vector of site numbers
site_numbers <- c("0034", "0038", "0045", "0060", "0065")

# Read and combine all 24-hour data files
epa_24hr_clean <- bind_rows(
  lapply(site_numbers, function(site) {
    read_csv(paste0("epa_pm25_site_", site, ".csv")) %>%
      filter(sample_duration == "24 HOUR") %>%
      mutate(
        site_number = site,
        date = as.Date(date_local),
        pm25 = sample_measurement
      ) %>%
      select(site_number, date, pm25)
  })
)

library(ggplot2)

unique_sites_24hr <- unique(epa_24hr_clean$site_number)

for (site in unique_sites_24hr) {
  site_data <- epa_24hr_clean %>% filter(site_number == site)

  p <- ggplot(site_data, aes(x = date, y = pm25)) +
    geom_line(color = "firebrick", linewidth = 0.6) +
    labs(
      title = paste("Daily PM2.5 (24-Hour Sample) - Site", site),
      x = "Date",
      y = expression("PM"[2.5]*" (µg/m³)")
    ) +
    scale_x_date(date_breaks = "1 month", date_labels = "%b\n%Y") +
    theme_minimal(base_size = 13)

  print(p)
  ggsave(filename = paste0("pm25_24hr_site_", site, ".png"), plot = p, width = 8, height = 4.5)
}
```


```{r}

# Count number of NA values in each column

na_counts_24hr <- sapply(epa_24hr_clean, function(col) sum(is.na(col)))
na_counts_24hr <- sort(na_counts_24hr, decreasing = TRUE)

# View NA count result
na_counts_24hr

# Step 6: Identify mostly NA columns

n_rows_24hr <- nrow(epa_24hr_clean)

# Threshold: Keep columns where fewer than 5% of values are not NA
mostly_na_cols_24hr <- names(na_counts_24hr[na_counts_24hr > 0 & na_counts_24hr < 0.05 * n_rows_24hr])

# View summary of those mostly NA columns

epa_24hr_clean %>%
  select(all_of(mostly_na_cols_24hr)) %>%
  summary()
```


```{r}
library(ggplot2)
library(dplyr)
library(readr)

# Loop over each site
for (site in site_numbers) {
  
  # Load data
  data <- read_csv(paste0("epa_pm25_site_", site, ".csv"))
  
  # Prepare 1-hour data: group and average by date
  hourly_avg <- data %>%
    filter(sample_duration == "1 HOUR", !is.na(sample_measurement)) %>%
    mutate(date = as.Date(date_local)) %>%
    group_by(date) %>%
    summarise(pm25_1hr_avg = mean(sample_measurement, na.rm = TRUE), .groups = "drop")
  
  # Prepare 24-hour data
  daily_data <- data %>%
    filter(sample_duration == "24 HOUR", !is.na(sample_measurement)) %>%
    mutate(date = as.Date(date_local)) %>%
    select(date, pm25_24hr = sample_measurement)
  
  # Join both datasets by date
  comparison_df <- left_join(hourly_avg, daily_data, by = "date") %>%
    filter(!is.na(pm25_1hr_avg), !is.na(pm25_24hr))  # Keep only rows with both values
  
  # Plot X-Y scatter
  p <- ggplot(comparison_df, aes(x = pm25_24hr, y = pm25_1hr_avg)) +
    geom_point(color = "steelblue", alpha = 0.7) +
    geom_smooth(method = "lm", se = FALSE, linetype = "dashed", color = "darkred") +
    labs(
      title = paste("EPA: 1-Hour Avg vs 24-Hour PM2.5 (Site", site, ")"),
      x = expression("24-Hour PM"[2.5]*" (µg/m³)"),
      y = expression("Daily Avg of 1-Hour PM"[2.5]*" (µg/m³)")
    ) +
    theme_minimal(base_size = 13)
  
  print(p)
}

```

# Loading CLEANinCLE Data for PM2.5
```{r}
library(readr)
library(dplyr)
library(lubridate)

# Load CLEANinCLE raw data
cleanincle_data <- read_csv("~/Documents/R_Projects/Air_pollution_Projects/CLEANinCLE_Raw_Air_Quality_Data_2024-11-2025-05.csv")

# Convert time column and filter for PM2.5 values
cleanincle_data <- cleanincle_data %>%
  filter(measure_name == "mc_pm2_5", !is.na(value)) %>%
  mutate(
    datetime = as.POSIXct(time, format = "%Y-%m-%d %H:%M:%S", tz = "America/New_York"),
    date = as.Date(datetime)
  )

# Preview the cleaned data
glimpse(cleanincle_data)
```

# Daily average PM2.5 from the optical sensor data.
```{r}
# Daily average PM2.5 values from CLEANinCLE
cleanincle_daily_avg <- cleanincle_data %>%
  group_by(date) %>%
  summarise(pm25_avg = mean(value, na.rm = TRUE)) %>%
  ungroup()
```

# Merging CLEANinCLE and EPA data by date.
```{r}
library(dplyr)
library(ggplot2)
library(readr)
library(lubridate)

# Vector of EPA site numbers
site_numbers <- c("0034", "0038", "0045", "0060", "0065")

# Step 1: Calculate CLEANinCLE daily average
cleanincle_daily_avg <- cleanincle_data %>%
  group_by(date) %>%
  summarise(pm25_cleanincle = mean(value, na.rm = TRUE), .groups = "drop")

# Step 2: Loop through each site and create comparison plot
for (site in site_numbers) {
  # Filter EPA data for this site
  epa_24hr_site <- epa_24hr_clean %>%
    filter(site_number == site) %>%
    select(date, pm25_epa = pm25)

  # Join CLEANinCLE with EPA data on date
  comparison_df <- inner_join(cleanincle_daily_avg, epa_24hr_site, by = "date")

  # Plot comparison
  p <- ggplot(comparison_df, aes(x = pm25_cleanincle, y = pm25_epa)) +
    geom_point(color = "steelblue", size = 2, alpha = 0.75) +
    geom_smooth(method = "lm", se = FALSE, color = "red", linewidth = 0.8) +
    labs(
      title = paste("Daily PM2.5 Comparison: CLEANinCLE vs EPA 24-Hour (Site", site, ")"),
      x = "CLEANinCLE Daily Avg PM2.5 (µg/m³)",
      y = "EPA 24-Hour PM2.5 (µg/m³)"
    ) +
    theme_minimal(base_size = 13)

  print(p)

  # Optionally save plot
  ggsave(
    filename = paste0("pm25_comparison_cleanincle_epa_site_", site, ".png"),
    plot = p,
    width = 8, height = 5
  )
}
```


```{r}
library(RAQSAPI)

epa_sites <- aqs_sites_by_county(
  stateFIPS = "39",    # Ohio
  countycode = "035",  # Cuyahoga County
  return_header = FALSE
)

# Preview to see latitude and longitude
head(epa_sites)

cleanincle_coords <- cleanincle_data %>%
  select(device_eui, latitude, longitude) %>%
  distinct()

# Preview
head(cleanincle_coords)

```


```{r}
# Load required libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(gridExtra)

# Wide-format data
epa_24hr_wide <- epa_24hr_clean %>%
  pivot_wider(names_from = site_number, values_from = pm25, values_fn = mean) %>%
  filter(rowSums(is.na(.)) < 3)

# valid site names (excluding 'date' column)
site_names <- setdiff(names(epa_24hr_wide), "date")
n_sites <- length(site_names)

# Consistent axis limits
axis_min <- 0
axis_max <- 28

# 25 plots with scatter + regression
plot_list <- list()

for (i in seq_len(n_sites)) {
  for (j in seq_len(n_sites)) {

    x_site <- site_names[j]
    y_site <- site_names[i]
    index <- (i - 1) * n_sites + j

    # Rename selected pair to x and y
    df_pair <- epa_24hr_wide %>%
      select(x = all_of(x_site), y = all_of(y_site)) %>%
      filter(!is.na(x) & !is.na(y))

    # Calculate R²
    r2_text <- if (nrow(df_pair) > 2) {
      r2 <- summary(lm(y ~ x, data = df_pair))$r.squared
      paste0("R² = ", round(r2, 2))
    } else {
      "R² = NA"
    }

    # Create plot with regression line
    p <- ggplot(df_pair, aes(x = x, y = y)) +
      geom_point(color = "steelblue", size = 2, alpha = 0.7) +
      geom_smooth(method = "lm", se = FALSE, color = "red", linewidth = 1.2) +
      geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
      coord_fixed(xlim = c(axis_min, axis_max), ylim = c(axis_min, axis_max)) +
      labs(
        x = paste("Site", x_site),
        y = paste("Site", y_site),
        subtitle = r2_text
      ) +
      theme_minimal(base_size = 14) +
      theme(
        plot.subtitle = element_text(hjust = 0.5, size = 12),
        axis.title = element_text(size = 12),
        axis.text = element_text(size = 10),
        plot.margin = margin(10, 10, 10, 10)
      )

    plot_list[[index]] <- p
  }
}

# Save 5x5 grid to a high-res PDF
pdf("EPA_PM25_Scatter_Regression.pdf", width = 22, height = 22)
grid.arrange(grobs = plot_list, ncol = n_sites, nrow = n_sites)
dev.off()
```


```{r}
library(dplyr)
library(ggplot2)
library(readr)
library(lubridate)

# Vector of co-located EPA site numbers
site_numbers <- c("0034", "0038", "0045", "0060", "0065")

# xDaily average for CLEANinCLE
cleanincle_daily_avg <- cleanincle_data %>%
  group_by(date) %>%
  summarise(pm25_cleanincle = mean(value, na.rm = TRUE), .groups = "drop")

# Step 2: Initialize empty plot list
plot_list <- list()

# Step 3: Loop through each co-located site
for (site in site_numbers) {
  
  # Filter EPA data for site
  epa_24hr_site <- epa_24hr_clean %>%
    filter(site_number == site) %>%
    select(date, pm25_epa = pm25)

  # Join with CLEANinCLE daily avg on date
  comparison_df <- inner_join(cleanincle_daily_avg, epa_24hr_site, by = "date") %>%
    filter(!is.na(pm25_cleanincle) & !is.na(pm25_epa))

  # Calculate R²
  r2_text <- if (nrow(comparison_df) > 2) {
    r2 <- summary(lm(pm25_epa ~ pm25_cleanincle, data = comparison_df))$r.squared
    paste0("R² = ", round(r2, 2))
  } else {
    "R² = NA"
  }

  # Create plot
  p <- ggplot(comparison_df, aes(x = pm25_cleanincle, y = pm25_epa)) +
    geom_point(color = "steelblue", size = 2, alpha = 0.75) +
    geom_smooth(method = "lm", se = FALSE, color = "red", linewidth = 0.9) +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
    coord_fixed(xlim = c(0, 28), ylim = c(0, 28)) +
    labs(
      title = paste("CLEANinCLE vs EPA 24-Hour PM2.5 (Site", site, ")"),
      subtitle = r2_text,
      x = "CLEANinCLE Daily Avg PM2.5 (µg/m³)",
      y = "EPA 24-Hour PM2.5 (µg/m³)"
    ) +
    theme_minimal(base_size = 13) +
    theme(
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 12, hjust = 0.5),
      axis.title = element_text(size = 12)
    )

  # Save to list
  plot_list[[site]] <- p
}

# Step 4: Save all site plots to one PDF
pdf("CLEANinCLE_vs_EPA_PM25_Comparison_All_Sites.pdf", width = 10, height = 6 * length(plot_list))
for (p in plot_list) print(p)
dev.off()
```


<pre>
```{r cleanincle-vs-epa, fig.height=6, fig.width=10, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)

site_numbers <- c("0034", "0038", "0045", "0060", "0065")

# CLEANinCLE daily average
cleanincle_daily_avg <- cleanincle_data %>%
  group_by(date) %>%
  summarise(pm25_cleanincle = mean(value, na.rm = TRUE), .groups = "drop")

# Create list to save PDF plots
plot_list <- list()

# Create and show/save plots
for (site in site_numbers) {
  # EPA filter data for site
  epa_24hr_site <- epa_24hr_clean %>%
    filter(site_number == site) %>%
    select(date, pm25_epa = pm25)

  # Join datasets by date
  comparison_df <- inner_join(cleanincle_daily_avg, epa_24hr_site, by = "date") %>%
    filter(!is.na(pm25_cleanincle) & !is.na(pm25_epa))

  # Compute R²
  r2_text <- if (nrow(comparison_df) > 2) {
    r2 <- summary(lm(pm25_epa ~ pm25_cleanincle, data = comparison_df))$r.squared
    paste0("R² = ", round(r2, 2))
  } else {
    "R² = NA"
  }

  # Generate plot
  p <- ggplot(comparison_df, aes(x = pm25_cleanincle, y = pm25_epa)) +
    geom_point(color = "steelblue", size = 2, alpha = 0.75) +
    geom_smooth(method = "lm", se = FALSE, color = "red", linewidth = 0.9) +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
    coord_fixed(xlim = c(0, 28), ylim = c(0, 28)) +
    labs(
      title = paste("CLEANinCLE vs EPA 24-Hour PM2.5 (Site", site, ")"),
      subtitle = r2_text,
      x = "CLEANinCLE Daily Avg PM2.5 (µg/m³)",
      y = "EPA 24-Hour PM2.5 (µg/m³)"
    ) +
    theme_minimal(base_size = 13) +
    theme(
      plot.title = element_text(size = 14, face = "bold"),
      plot.subtitle = element_text(size = 12, hjust = 0.5),
      axis.title = element_text(size = 12)
    )

  # Show inline
  print(p)

  # Save individual PNG
  ggsave(filename = paste0("cleanincle_vs_epa_", site, ".png"), plot = p, width = 8, height = 6)

  # Store for multi-page PDF
  plot_list[[site]] <- p
}

# Save all plots to a single PDF
pdf("cleanincle_vs_epa_all_sites.pdf", width = 10, height = 6)
for (p in plot_list) print(p)
dev.off()
```


```{r epa-5x5-filter-grid, fig.width=22, fig.height=22, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(tidyr)
library(gridExtra)

# Step 1: Reshape to wide format (site columns)
epa_wide <- epa_24hr_clean %>%
  select(date, site_number, pm25) %>%
  pivot_wider(names_from = site_number, values_from = pm25, values_fn = mean) %>%
  filter(rowSums(is.na(.)) < 3)

# Step 2: Define site list
site_names <- sort(setdiff(names(epa_wide), "date"))
n_sites <- length(site_names)
axis_min <- 0
axis_max <- 28

# Step 3: Build plot matrix
plot_matrix <- vector("list", n_sites * n_sites)

for (i in seq_len(n_sites)) {
  for (j in seq_len(n_sites)) {
    x_site <- site_names[j]
    y_site <- site_names[i]
    index <- (i - 1) * n_sites + j

    df_pair <- epa_wide %>%
      select(x = all_of(x_site), y = all_of(y_site)) %>%
      filter(!is.na(x) & !is.na(y))

    r2_text <- if (nrow(df_pair) > 2) {
      r2 <- summary(lm(y ~ x, data = df_pair))$r.squared
      paste0("R² = ", round(r2, 2))
    } else {
      "R² = NA"
    }

    p <- ggplot(df_pair, aes(x = x, y = y)) +
      geom_point(color = "steelblue", alpha = 0.7, size = 1.8) +
      geom_smooth(method = "lm", se = FALSE, color = "red", linewidth = 1) +
      geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
      coord_fixed(xlim = c(axis_min, axis_max), ylim = c(axis_min, axis_max)) +
      labs(
        x = paste("Site", x_site),
        y = paste("Site", y_site),
        subtitle = r2_text
      ) +
      theme_minimal(base_size = 12) +
      theme(
        plot.subtitle = element_text(size = 10, hjust = 0.5),
        axis.title = element_text(size = 10),
        axis.text = element_text(size = 9),
        plot.margin = margin(5, 5, 5, 5)
      )

    plot_matrix[[index]] <- p
  }
}

# Step 4: Arrange and display plot in Markdown output
grid_plot <- grid.arrange(grobs = plot_matrix, ncol = n_sites, nrow = n_sites)
print(grid_plot)

# Step 5: Also save to a high-quality PDF
ggsave("EPA_Filter_PM25_5x5_Comparison.pdf", plot = grid_plot, width = 22, height = 22)
```


```{r}

# Load required libraries
library(dplyr)
library(tidyr)
library(ggplot2)
library(gridExtra)

# STEP 1: Prepare wide-format data (each site in a separate column)
epa_wide <- epa_24hr_clean %>%
  select(date, site_number, pm25) %>%
  pivot_wider(names_from = site_number, values_from = pm25, values_fn = mean)

# STEP 2: Set up variables
site_names <- setdiff(names(epa_wide), "date")  # all site columns
n_sites <- length(site_names)
axis_min <- 0
axis_max <- 28  # set based on observed max in summary

# STEP 3: Create plot matrix
plot_matrix <- vector("list", n_sites * n_sites)

for (i in seq_len(n_sites)) {
  for (j in seq_len(n_sites)) {
    y_site <- site_names[i]
    x_site <- site_names[j]
    index <- (i - 1) * n_sites + j

    df_pair <- epa_wide %>%
      select(x = all_of(x_site), y = all_of(y_site)) %>%
      filter(!is.na(x) & !is.na(y))

    if (i == j) {
      # Diagonal: 1:1 scatterplot of site against itself
      p <- ggplot(df_pair, aes(x = x, y = x)) +
        geom_point(color = "gray40", size = 1.8, alpha = 0.6) +
        geom_abline(slope = 1, intercept = 0, linetype = "solid", color = "black") +
        coord_fixed(xlim = c(axis_min, axis_max), ylim = c(axis_min, axis_max)) +
        labs(
          x = paste("Site", x_site),
          y = paste("Site", x_site),
          subtitle = "1:1 Line"
        ) +
        theme_minimal(base_size = 12) +
        theme(
          plot.subtitle = element_text(size = 10, hjust = 0.5),
          axis.title = element_text(size = 10),
          axis.text = element_text(size = 9),
          plot.margin = margin(6, 6, 6, 6)
        )
    } else {
      # Off-diagonal: scatter + regression + R²
      r2_text <- if (nrow(df_pair) > 2) {
        r2 <- summary(lm(y ~ x, data = df_pair))$r.squared
        paste0("R² = ", round(r2, 2))
      } else {
        "R² = NA"
      }

      p <- ggplot(df_pair, aes(x = x, y = y)) +
        geom_point(color = "steelblue", size = 1.8, alpha = 0.7) +
        geom_smooth(method = "lm", se = FALSE, color = "red", linewidth = 1) +
        geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
        coord_fixed(xlim = c(axis_min, axis_max), ylim = c(axis_min, axis_max)) +
        labs(
          x = paste("Site", x_site),
          y = paste("Site", y_site),
          subtitle = r2_text
        ) +
        theme_minimal(base_size = 12) +
        theme(
          plot.subtitle = element_text(size = 10, hjust = 0.5),
          axis.title = element_text(size = 10),
          axis.text = element_text(size = 9),
          plot.margin = margin(6, 6, 6, 6)
        )
    }

    plot_matrix[[index]] <- p
  }
}

# STEP 4: Arrange and display in 5x5 matrix
grid_plot <- grid.arrange(grobs = plot_matrix, ncol = n_sites, nrow = n_sites)
print(grid_plot)

# STEP 5: Save to high-resolution PDF
ggsave("EPA_PM25_5x5_FullMatrix.pdf", plot = grid_plot, width = 22, height = 22)
```

```{r cleanincle-5x5-optical, fig.width=22, fig.height=22, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(tidyr)
library(gridExtra)

# Step 1: Identify top 5 devices with the most non-NA PM2.5 readings
top_devices <- cleanincle_data %>%
  group_by(device_number) %>%
  summarise(count = sum(!is.na(value)), .groups = "drop") %>%
  arrange(desc(count)) %>%
  slice_head(n = 5) %>%
  pull(device_number)

# Step 2: Reshape to wide format for selected devices
cleanincle_wide <- cleanincle_data %>%
  filter(device_number %in% top_devices) %>%
  group_by(device_number, date) %>%
  summarise(pm25 = mean(value, na.rm = TRUE), .groups = "drop") %>%
  pivot_wider(names_from = device_number, values_from = pm25)

# Step 3: Prepare for matrix plotting
site_names <- names(cleanincle_wide)[-1]  # exclude 'date'
n_sites <- length(site_names)

# Handle case where devices are missing or all-NA
if (n_sites == 0) {
  stop(" No valid devices found for plotting.")
}

axis_min <- 0
axis_max <- 28
plot_matrix <- vector("list", n_sites * n_sites)

# Step 4: Loop through device pairs to generate plots
for (i in seq_len(n_sites)) {
  for (j in seq_len(n_sites)) {
    x_site <- site_names[j]
    y_site <- site_names[i]
    index <- (i - 1) * n_sites + j

    df_pair <- cleanincle_wide %>%
      select(x = all_of(x_site), y = all_of(y_site)) %>%
      filter(!is.na(x) & !is.na(y))

    r2_text <- if (nrow(df_pair) > 2) {
      r2 <- summary(lm(y ~ x, data = df_pair))$r.squared
      paste0("R² = ", round(r2, 2))
    } else {
      "R² = NA"
    }

    p <- ggplot(df_pair, aes(x = x, y = y)) +
      geom_point(color = "darkorange", alpha = 0.7, size = 1.8) +
      geom_smooth(method = "lm", se = FALSE, color = "red", linewidth = 1) +
      geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
      coord_fixed(xlim = c(axis_min, axis_max), ylim = c(axis_min, axis_max)) +
      labs(
        x = paste("Device", x_site),
        y = paste("Device", y_site),
        subtitle = r2_text
      ) +
      theme_minimal(base_size = 12) +
      theme(
        plot.subtitle = element_text(size = 10, hjust = 0.5),
        axis.title = element_text(size = 10),
        axis.text = element_text(size = 9),
        plot.margin = margin(5, 5, 5, 5)
      )

    plot_matrix[[index]] <- p
  }
}

# Step 5: Display inline and save to PDF
grid_plot <- grid.arrange(grobs = plot_matrix, ncol = n_sites, nrow = n_sites)
print(grid_plot)

ggsave("CLEANinCLE_Optical_PM25_Top5_5x5_Comparison.pdf", plot = grid_plot, width = 22, height = 22)
```


```{r}
# Load required libraries
library(dplyr)
library(readr)

# If needed: combined EPA data from earlier (already loaded in your session)
# epa_all_data <- bind_rows(epa_data_list, .id = "site_number")

# Step 1: Create a full site info table from the combined EPA data
epa_sites <- epa_all_data %>%
  select(state_code, county_code, site_number, longitude, latitude) %>%
  distinct()

# Step 2: Filter to just the 5 sites of interest
target_sites <- c("0034", "0038", "0045", "0060", "0065")

epa_five_sites <- epa_sites %>%
  filter(site_number %in% target_sites)

# Step 3 (Optional): View or save
print(epa_five_sites)

# Optional: Save to CSV
#write_csv(epa_five_sites, "epa_5_site_locations.csv")
```


```{r}
library(dplyr)
library(readr)

# Load the data (if not already loaded)
cleanincle_data <- read_csv("CLEANinCLE_Raw_Air_Quality_Data_2024-11-2025-05.csv")

# Create a site info table
cleanincle_sites <- cleanincle_data %>%
  select(location_name, device_number, device_eui, longitude, latitude) %>%
  distinct()

# View the table
print(cleanincle_sites)

# Optional: Save to CSV
#write_csv(cleanincle_sites, "cleancle_site_locations.csv")
```

```{r}
# Load required libraries
library(dplyr)
library(readr)
library(geosphere)

# -------- STEP 1: Combine EPA Site Data (if not already) --------

# Assuming epa_data_list has all 5 sites loaded using RAQSAPI
epa_all_data <- bind_rows(epa_data_list, .id = "site_number")

# Save to CSV (optional)
write_csv(epa_all_data, "epa_pm25_site_combined.csv")

# -------- STEP 2: Load Data --------

# Load EPA data
epa_data <- read_csv("epa_pm25_site_combined.csv")

# Load CLEANinCLE data (replace filename with actual if different)
cleanincle_data <- read_csv("CLEANinCLE_Raw_Air_Quality_Data_2024-11-2025-05.csv")

# -------- STEP 3: Extract Unique Site Coordinates --------

epa_sites <- epa_data %>%
  select(site_number, latitude, longitude) %>%
  distinct()

cleanincle_sites <- cleanincle_data %>%
  select(location_name, device_number, device_eui, latitude, longitude) %>%
  distinct()

# -------- STEP 3.5: Write RDS and CSVs with site names and coordinates ---

saveRDS(epa_sites, "Maps/epa_sites.rds")
write_csv(epa_sites, "Maps/epa_sites.csv")

saveRDS(cleanincle_sites, "Maps/cleanincle_sites.rds")
write_csv(cleanincle_sites, "Maps/cleanincle_sites.csv")

# -------- STEP 4: Compute All Pairwise Distances --------

distance_table <- expand.grid(
  epa_site = epa_sites$site_number,
  cleancle_device = cleanincle_sites$device_number,
  stringsAsFactors = FALSE
) %>%
  left_join(epa_sites, by = c("epa_site" = "site_number")) %>%
  left_join(cleanincle_sites, by = c("cleancle_device" = "device_number")) %>%
  mutate(
    distance_km = distHaversine(
      cbind(longitude.x, latitude.x),
      cbind(longitude.y, latitude.y)
    ) / 1000
  ) %>%
  select(
    epa_site,
    epa_lat = latitude.x,
    epa_lon = longitude.x,
    cleancle_location = location_name,
    cleancle_device,
    device_eui,
    cleancle_lat = latitude.y,
    cleancle_lon = longitude.y,
    distance_km
  )

# -------- STEP 5: View and Save the Full Table --------

print(distance_table)

# Save full distance table to CSV
write_csv(distance_table, "epa_cleanincle_all_pairwise_distances.csv")

```




```{r}
# Load required libraries
library(dplyr)
library(readr)
library(geosphere)

# -------- STEP 1: Combine and Save EPA Site Data --------
# Assuming 'epa_data_list' already contains all 5 sites

epa_all_data <- bind_rows(epa_data_list, .id = "site_number")

# Save EPA data for future use
write_csv(epa_all_data, "epa_pm25_site_combined.csv")

# -------- STEP 2: Load EPA and CLEANinCLE Datasets --------

# Load the just-saved EPA file
epa_data <- read_csv("epa_pm25_site_combined.csv")

# Load CLEANinCLE file (replace with your exact path if needed)
cleanincle_data <- read_csv("CLEANinCLE_Raw_Air_Quality_Data_2024-11-2025-05.csv")

# -------- STEP 3: Extract Unique Locations --------

epa_sites <- epa_data %>%
  select(site_number, latitude, longitude) %>%
  distinct()

cleanincle_sites <- cleanincle_data %>%
  select(location_name, device_number, device_eui, latitude, longitude) %>%
  distinct()

# Compute Pairwise Distances --------

distance_table <- expand.grid(
  epa_site = epa_sites$site_number,
  cleancle_device = cleanincle_sites$device_number
) %>%
  left_join(epa_sites, by = c("epa_site" = "site_number")) %>%
  left_join(cleanincle_sites, by = c("cleancle_device" = "device_number")) %>%
  mutate(
    distance_km = distHaversine(
      cbind(longitude.x, latitude.x),
      cbind(longitude.y, latitude.y)
    ) / 1000
  )

#write_csv(distance_table, "epa_all_distances.csv")

# Closest Device to Each EPA Site --------

closest_matches <- distance_table %>%
  group_by(epa_site) %>%
  slice_min(distance_km, n = 1) %>%
  ungroup() %>%
  select(
    epa_site,
    epa_lat = latitude.x,
    epa_lon = longitude.x,
    cleancle_location = location_name,
    device_number = cleancle_device,
    device_eui,
    cleancle_lat = latitude.y,
    cleancle_lon = longitude.y,
    distance_km
  )

# View and Save Result 

print(closest_matches)

write_csv(closest_matches, "epa_closest_cleanincle_devices.csv")

```


```{r}


```


Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
